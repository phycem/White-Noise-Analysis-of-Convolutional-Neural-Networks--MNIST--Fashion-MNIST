{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "93840a30",
      "metadata": {
        "id": "93840a30"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "#added for Net model MNIST dataset\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "#added for Net model Fashion-MNIST\n",
        "from tensorflow.keras import layers\n",
        "#added for Model model MNIST dataset\n",
        "import numpy as np\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "import os\n",
        "#added for Model Fashion-MNIST dataset\n",
        "from sklearn.model_selection import train_test_split\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bb40b542",
      "metadata": {
        "id": "bb40b542"
      },
      "outputs": [],
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
        "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.fc1 = nn.Linear(128 * 7 * 7, 512)\n",
        "        self.fc2 = nn.Linear(512, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = self.pool(F.relu(self.conv3(x)))\n",
        "        x = x.view(-1, 128 * 7 * 7)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.softmax(self.fc2(x), dim=1)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c0480c83",
      "metadata": {
        "id": "c0480c83"
      },
      "outputs": [],
      "source": [
        "class Model(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Model, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 20, 5, 1)\n",
        "        self.conv2 = nn.Conv2d(20, 50, 5, 1)\n",
        "        self.fc1 = nn.Linear(4*4*50, 500)\n",
        "        self.fc2 = nn.Linear(500,10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x_1 = F.relu(self.conv1(x))\n",
        "        x = F.max_pool2d(x_1, 2, 2)\n",
        "        x_2 = F.relu(self.conv2(x))\n",
        "        x = F.max_pool2d(x_2, 2, 2)\n",
        "        x = x.view(-1, 4*4*50)\n",
        "        x_3 = F.relu(self.fc1(x))\n",
        "        h = F.softmax(self.fc2(x_3),dim=1)\n",
        "        return h, x_3, x_2, x_1"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d05c8af8",
      "metadata": {
        "id": "d05c8af8"
      },
      "source": [
        "## When training the models, I consider small batch size to help the models generalize better by reducing the effects of noise and providing more diverse examples in each update step. However, smaller batch size resulted in slower training times for my NET CNN model and so is less efficient use of hardware resources.\n",
        "\n",
        "## The paper considers 256 batch size which can cause potential overfitting depending of images' complexity and size. "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c0d96107",
      "metadata": {
        "id": "c0d96107"
      },
      "source": [
        "# Train NET with MNIST keras\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1928de50",
      "metadata": {
        "id": "1928de50",
        "outputId": "ea841b94-b3b2-40e8-cfd2-077906a0b9fa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n",
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 69s 36ms/step - loss: 0.1185 - accuracy: 0.9633 - val_loss: 0.0507 - val_accuracy: 0.9835\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 66s 35ms/step - loss: 0.0390 - accuracy: 0.9874 - val_loss: 0.0247 - val_accuracy: 0.9915\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 64s 34ms/step - loss: 0.0283 - accuracy: 0.9910 - val_loss: 0.0257 - val_accuracy: 0.9911\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 67s 36ms/step - loss: 0.0209 - accuracy: 0.9934 - val_loss: 0.0339 - val_accuracy: 0.9898\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 72s 38ms/step - loss: 0.0175 - accuracy: 0.9944 - val_loss: 0.0267 - val_accuracy: 0.9922\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 86s 46ms/step - loss: 0.0145 - accuracy: 0.9951 - val_loss: 0.0289 - val_accuracy: 0.9919\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 80s 43ms/step - loss: 0.0128 - accuracy: 0.9961 - val_loss: 0.0271 - val_accuracy: 0.9923\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 76s 41ms/step - loss: 0.0107 - accuracy: 0.9963 - val_loss: 0.0287 - val_accuracy: 0.9924\n",
            "Epoch 9/10\n",
            "1875/1875 [==============================] - 79s 42ms/step - loss: 0.0099 - accuracy: 0.9966 - val_loss: 0.0343 - val_accuracy: 0.9908\n",
            "Epoch 10/10\n",
            "1875/1875 [==============================] - 97s 52ms/step - loss: 0.0081 - accuracy: 0.9975 - val_loss: 0.0339 - val_accuracy: 0.9923\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x2301071d550>"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "# Load MNIST dataset\n",
        "(train_images, train_labels), (test_images, test_labels) = keras.datasets.mnist.load_data()\n",
        "\n",
        "# Reshape and normalize data\n",
        "train_images = train_images.reshape(train_images.shape[0], 28, 28, 1).astype('float32') / 255.0\n",
        "test_images = test_images.reshape(test_images.shape[0], 28, 28, 1).astype('float32') / 255.0\n",
        "\n",
        "# Define the model\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu', padding='same', input_shape=(28, 28, 1)),\n",
        "    keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "    keras.layers.Conv2D(filters=64, kernel_size=3, activation='relu', padding='same'),\n",
        "    keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "    keras.layers.Conv2D(filters=128, kernel_size=3, activation='relu', padding='same'),\n",
        "    keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "    keras.layers.Flatten(),\n",
        "    keras.layers.Dense(512, activation='relu'),\n",
        "    keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(train_images, train_labels, epochs=10, validation_data=(test_images, test_labels))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "0b959cfa",
      "metadata": {
        "id": "0b959cfa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7382cbc-a289-4cfa-e81c-1ce8ef800631"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n",
            "Training model for 5 epochs...\n",
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 143s 75ms/step - loss: 0.1155 - accuracy: 0.9635 - val_loss: 0.0438 - val_accuracy: 0.9857\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 138s 73ms/step - loss: 0.0395 - accuracy: 0.9879 - val_loss: 0.0294 - val_accuracy: 0.9906\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 134s 72ms/step - loss: 0.0279 - accuracy: 0.9912 - val_loss: 0.0355 - val_accuracy: 0.9892\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 140s 75ms/step - loss: 0.0210 - accuracy: 0.9937 - val_loss: 0.0276 - val_accuracy: 0.9907\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 135s 72ms/step - loss: 0.0172 - accuracy: 0.9944 - val_loss: 0.0285 - val_accuracy: 0.9904\n",
            "313/313 [==============================] - 5s 17ms/step - loss: 0.0285 - accuracy: 0.9904\n",
            "Validation accuracy for 5 epochs: 0.9904000163078308\n",
            "\n",
            "Training model for 10 epochs...\n",
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 133s 71ms/step - loss: 0.0154 - accuracy: 0.9949 - val_loss: 0.0245 - val_accuracy: 0.9929\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 129s 69ms/step - loss: 0.0120 - accuracy: 0.9961 - val_loss: 0.0337 - val_accuracy: 0.9919\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 132s 70ms/step - loss: 0.0100 - accuracy: 0.9967 - val_loss: 0.0323 - val_accuracy: 0.9912\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 135s 72ms/step - loss: 0.0099 - accuracy: 0.9969 - val_loss: 0.0385 - val_accuracy: 0.9907\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 134s 71ms/step - loss: 0.0081 - accuracy: 0.9976 - val_loss: 0.0391 - val_accuracy: 0.9913\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 129s 69ms/step - loss: 0.0085 - accuracy: 0.9974 - val_loss: 0.0423 - val_accuracy: 0.9921\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 135s 72ms/step - loss: 0.0083 - accuracy: 0.9976 - val_loss: 0.0301 - val_accuracy: 0.9934\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 136s 73ms/step - loss: 0.0083 - accuracy: 0.9973 - val_loss: 0.0364 - val_accuracy: 0.9932\n",
            "Epoch 9/10\n",
            "1875/1875 [==============================] - 139s 74ms/step - loss: 0.0072 - accuracy: 0.9981 - val_loss: 0.0400 - val_accuracy: 0.9913\n",
            "Epoch 10/10\n",
            "1875/1875 [==============================] - 138s 73ms/step - loss: 0.0058 - accuracy: 0.9982 - val_loss: 0.0379 - val_accuracy: 0.9929\n",
            "313/313 [==============================] - 6s 19ms/step - loss: 0.0379 - accuracy: 0.9929\n",
            "Validation accuracy for 10 epochs: 0.992900013923645\n",
            "\n",
            "Training model for 15 epochs...\n",
            "Epoch 1/15\n",
            "1875/1875 [==============================] - 138s 73ms/step - loss: 0.0070 - accuracy: 0.9980 - val_loss: 0.0377 - val_accuracy: 0.9927\n",
            "Epoch 2/15\n",
            "1875/1875 [==============================] - 136s 72ms/step - loss: 0.0059 - accuracy: 0.9983 - val_loss: 0.0570 - val_accuracy: 0.9915\n",
            "Epoch 3/15\n",
            "1875/1875 [==============================] - 135s 72ms/step - loss: 0.0078 - accuracy: 0.9979 - val_loss: 0.0420 - val_accuracy: 0.9929\n",
            "Epoch 4/15\n",
            "1875/1875 [==============================] - 132s 70ms/step - loss: 0.0056 - accuracy: 0.9984 - val_loss: 0.0523 - val_accuracy: 0.9920\n",
            "Epoch 5/15\n",
            "1875/1875 [==============================] - 136s 72ms/step - loss: 0.0069 - accuracy: 0.9983 - val_loss: 0.0412 - val_accuracy: 0.9933\n",
            "Epoch 6/15\n",
            "1875/1875 [==============================] - 134s 72ms/step - loss: 0.0047 - accuracy: 0.9986 - val_loss: 0.0547 - val_accuracy: 0.9909\n",
            "Epoch 7/15\n",
            "1875/1875 [==============================] - 137s 73ms/step - loss: 0.0068 - accuracy: 0.9983 - val_loss: 0.0425 - val_accuracy: 0.9941\n",
            "Epoch 8/15\n",
            "1875/1875 [==============================] - 135s 72ms/step - loss: 0.0059 - accuracy: 0.9983 - val_loss: 0.0446 - val_accuracy: 0.9928\n",
            "Epoch 9/15\n",
            "1875/1875 [==============================] - 131s 70ms/step - loss: 0.0055 - accuracy: 0.9985 - val_loss: 0.0568 - val_accuracy: 0.9919\n",
            "Epoch 10/15\n",
            "1875/1875 [==============================] - 131s 70ms/step - loss: 0.0063 - accuracy: 0.9984 - val_loss: 0.0496 - val_accuracy: 0.9929\n",
            "Epoch 11/15\n",
            "1875/1875 [==============================] - 134s 71ms/step - loss: 0.0029 - accuracy: 0.9993 - val_loss: 0.0724 - val_accuracy: 0.9922\n",
            "Epoch 12/15\n",
            "1875/1875 [==============================] - 133s 71ms/step - loss: 0.0077 - accuracy: 0.9983 - val_loss: 0.0465 - val_accuracy: 0.9931\n",
            "Epoch 13/15\n",
            "1875/1875 [==============================] - 134s 72ms/step - loss: 0.0031 - accuracy: 0.9992 - val_loss: 0.0600 - val_accuracy: 0.9929\n",
            "Epoch 14/15\n",
            "1875/1875 [==============================] - 132s 71ms/step - loss: 0.0076 - accuracy: 0.9982 - val_loss: 0.0616 - val_accuracy: 0.9932\n",
            "Epoch 15/15\n",
            "1875/1875 [==============================] - 132s 70ms/step - loss: 0.0056 - accuracy: 0.9987 - val_loss: 0.0705 - val_accuracy: 0.9930\n",
            "313/313 [==============================] - 5s 17ms/step - loss: 0.0705 - accuracy: 0.9930\n",
            "Validation accuracy for 15 epochs: 0.9929999709129333\n",
            "\n",
            "Best model validation accuracy: 0.9929999709129333\n",
            "\n",
            "Best model saved to best_model.h5\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.engine.sequential.Sequential at 0x7f9e4d8e6710>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "def train_mnist(num_epochs):\n",
        "    # Load MNIST dataset\n",
        "    (train_images, train_labels), (test_images, test_labels) = keras.datasets.mnist.load_data()\n",
        "\n",
        "    # Reshape and normalize data\n",
        "    train_images = train_images.reshape(train_images.shape[0], 28, 28, 1).astype('float32') / 255.0\n",
        "    test_images = test_images.reshape(test_images.shape[0], 28, 28, 1).astype('float32') / 255.0\n",
        "\n",
        "    # Define the model\n",
        "    model = keras.Sequential([\n",
        "        keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu', padding='same', input_shape=(28, 28, 1)),\n",
        "        keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "        keras.layers.Conv2D(filters=64, kernel_size=3, activation='relu', padding='same'),\n",
        "        keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "        keras.layers.Conv2D(filters=128, kernel_size=3, activation='relu', padding='same'),\n",
        "        keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "        keras.layers.Flatten(),\n",
        "        keras.layers.Dense(512, activation='relu'),\n",
        "        keras.layers.Dense(10, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    best_model = None\n",
        "    best_val_acc = 0.0\n",
        "\n",
        "    # Try different number of epochs and keep track of the best model\n",
        "    for epoch in num_epochs:\n",
        "        print(f'Training model for {epoch} epochs...')\n",
        "        model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "        model.fit(train_images, train_labels, epochs=epoch, validation_data=(test_images, test_labels))\n",
        "        _, val_acc = model.evaluate(test_images, test_labels)\n",
        "        if val_acc > best_val_acc:\n",
        "            best_val_acc = val_acc\n",
        "            best_model = model\n",
        "        print(f'Validation accuracy for {epoch} epochs: {val_acc}\\n')\n",
        "\n",
        "    print(f'Best model validation accuracy: {best_val_acc}\\n')\n",
        "\n",
        "       # Save the best model to a file\n",
        "    best_model_path = 'best_model.h5'\n",
        "    if os.path.exists(best_model_path):\n",
        "        os.remove(best_model_path)\n",
        "    best_model.save(best_model_path)\n",
        "    print(f'Best model saved to {best_model_path}\\n')\n",
        "\n",
        "    return best_model\n",
        "\n",
        "train_mnist([5, 10, 15])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ea6d7c8b",
      "metadata": {
        "id": "ea6d7c8b",
        "outputId": "92803bbc-dffe-42ce-d294-ffacd187f32f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training model for 5 epochs...\n",
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 79s 41ms/step - loss: 0.1124 - accuracy: 0.9638 - val_loss: 0.0335 - val_accuracy: 0.9890\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 77s 41ms/step - loss: 0.0390 - accuracy: 0.9883 - val_loss: 0.0286 - val_accuracy: 0.9906\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 79s 42ms/step - loss: 0.0289 - accuracy: 0.9910 - val_loss: 0.0253 - val_accuracy: 0.9921\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 84s 45ms/step - loss: 0.0215 - accuracy: 0.9933 - val_loss: 0.0267 - val_accuracy: 0.9916\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 79s 42ms/step - loss: 0.0168 - accuracy: 0.9947 - val_loss: 0.0279 - val_accuracy: 0.9918\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.0279 - accuracy: 0.9918\n",
            "Validation accuracy for 5 epochs: 0.9918000102043152\n",
            "\n",
            "Training model for 10 epochs...\n",
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 72s 38ms/step - loss: 0.0068 - accuracy: 0.9984 - val_loss: 0.0580 - val_accuracy: 0.9934\n",
            "Epoch 14/15\n",
            "1875/1875 [==============================] - 84s 45ms/step - loss: 0.0057 - accuracy: 0.9989 - val_loss: 0.0531 - val_accuracy: 0.9938\n",
            "Epoch 15/15\n",
            "1875/1875 [==============================] - 70s 37ms/step - loss: 0.0062 - accuracy: 0.9990 - val_loss: 0.0709 - val_accuracy: 0.9921\n",
            "313/313 [==============================] - 5s 14ms/step - loss: 0.0709 - accuracy: 0.9921\n",
            "Validation accuracy for 15 epochs: 0.9921000003814697\n",
            "\n",
            "Best model validation accuracy: 0.9921000003814697\n",
            "\n"
          ]
        }
      ],
      "source": [
        "best_model = train_mnist([5, 10, 15])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "63483cdc",
      "metadata": {
        "id": "63483cdc"
      },
      "source": [
        "# Train NET with Fashion-MNIST "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a52fd6ab",
      "metadata": {
        "id": "a52fd6ab",
        "outputId": "8daa52a6-98b3-44cd-aa0c-b93203a48a34"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "29515/29515 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26421880/26421880 [==============================] - 1s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "5148/5148 [==============================] - 0s 0s/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4422102/4422102 [==============================] - 0s 0us/step\n",
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 60s 31ms/step - loss: 0.4557 - accuracy: 0.8313 - val_loss: 0.3404 - val_accuracy: 0.8744\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 66s 35ms/step - loss: 0.2930 - accuracy: 0.8917 - val_loss: 0.2883 - val_accuracy: 0.8969\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 53s 28ms/step - loss: 0.2487 - accuracy: 0.9063 - val_loss: 0.2589 - val_accuracy: 0.9043\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 49s 26ms/step - loss: 0.2142 - accuracy: 0.9190 - val_loss: 0.2741 - val_accuracy: 0.8988\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 52s 27ms/step - loss: 0.1893 - accuracy: 0.9284 - val_loss: 0.2718 - val_accuracy: 0.9059\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 44s 24ms/step - loss: 0.1650 - accuracy: 0.9384 - val_loss: 0.2678 - val_accuracy: 0.9080\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 47s 25ms/step - loss: 0.1453 - accuracy: 0.9453 - val_loss: 0.2628 - val_accuracy: 0.9124\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 56s 30ms/step - loss: 0.1264 - accuracy: 0.9520 - val_loss: 0.3060 - val_accuracy: 0.9109\n",
            "Epoch 9/10\n",
            "1875/1875 [==============================] - 50s 26ms/step - loss: 0.1116 - accuracy: 0.9576 - val_loss: 0.3038 - val_accuracy: 0.9113\n",
            "Epoch 10/10\n",
            "1875/1875 [==============================] - 51s 27ms/step - loss: 0.0988 - accuracy: 0.9624 - val_loss: 0.3123 - val_accuracy: 0.9071\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.3123 - accuracy: 0.9071\n",
            "Test accuracy: 0.9071000218391418\n"
          ]
        }
      ],
      "source": [
        "# Load the Fashion-MNIST dataset\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
        "\n",
        "# Preprocess the data\n",
        "x_train = x_train.astype(\"float32\") / 255.0\n",
        "x_test = x_test.astype(\"float32\") / 255.0\n",
        "x_train = x_train.reshape(-1, 28, 28, 1)\n",
        "x_test = x_test.reshape(-1, 28, 28, 1)\n",
        "\n",
        "# Define the model\n",
        "model = keras.Sequential(\n",
        "    [\n",
        "        layers.Conv2D(32, kernel_size=3, activation=\"relu\", input_shape=(28, 28, 1)),\n",
        "        layers.MaxPooling2D(),\n",
        "        layers.Conv2D(64, kernel_size=3, activation=\"relu\"),\n",
        "        layers.MaxPooling2D(),\n",
        "        layers.Conv2D(128, kernel_size=3, activation=\"relu\"),\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(512, activation=\"relu\"),\n",
        "        layers.Dense(10, activation=\"softmax\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(x_train, y_train, epochs=10, validation_data=(x_test, y_test))\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
        "print(\"Test accuracy:\", test_acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c98ac94e",
      "metadata": {
        "id": "c98ac94e"
      },
      "outputs": [],
      "source": [
        "def find_best_epoch():\n",
        "    # Load the Fashion-MNIST dataset\n",
        "    (x_train, y_train), (x_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
        "\n",
        "    # Preprocess the data\n",
        "    x_train = x_train.astype(\"float32\") / 255.0\n",
        "    x_test = x_test.astype(\"float32\") / 255.0\n",
        "    x_train = x_train.reshape(-1, 28, 28, 1)\n",
        "    x_test = x_test.reshape(-1, 28, 28, 1)\n",
        "\n",
        "    # Define the model\n",
        "    model = keras.Sequential(\n",
        "        [\n",
        "            layers.Conv2D(32, kernel_size=3, activation=\"relu\", input_shape=(28, 28, 1)),\n",
        "            layers.MaxPooling2D(),\n",
        "            layers.Conv2D(64, kernel_size=3, activation=\"relu\"),\n",
        "            layers.MaxPooling2D(),\n",
        "            layers.Conv2D(128, kernel_size=3, activation=\"relu\"),\n",
        "            layers.Flatten(),\n",
        "            layers.Dense(512, activation=\"relu\"),\n",
        "            layers.Dense(10, activation=\"softmax\"),\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "    # Train the model with different number of epochs\n",
        "    epochs = [5, 10, 15, 20]\n",
        "    best_epoch = 0\n",
        "    best_val_acc = 0.0\n",
        "    for epoch in epochs:\n",
        "        history = model.fit(x_train, y_train, epochs=epoch, validation_data=(x_test, y_test))\n",
        "        val_acc = history.history['val_accuracy'][-1]\n",
        "        print(f\"Epoch {epoch} validation accuracy: {val_acc:.4f}\")\n",
        "        if val_acc > best_val_acc:\n",
        "            best_val_acc = val_acc\n",
        "            best_epoch = epoch\n",
        "\n",
        "    # Re-train the model with the best number of epochs\n",
        "    print(f\"\\nBest epoch: {best_epoch}\")\n",
        "    model.fit(x_train, y_train, epochs=best_epoch, validation_data=(x_test, y_test))\n",
        "\n",
        "    # Evaluate the model\n",
        "    test_loss, test_acc = model.evaluate(x_test, y_test)\n",
        "    print(\"Test accuracy:\", test_acc)\n",
        "\n",
        "    return best_epoch\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "26ae1217",
      "metadata": {
        "id": "26ae1217",
        "outputId": "9d89d216-69ae-4290-cee6-47b82c2d74f6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 54s 28ms/step - loss: 0.4415 - accuracy: 0.8367 - val_loss: 0.3240 - val_accuracy: 0.8837\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 51s 27ms/step - loss: 0.2908 - accuracy: 0.8925 - val_loss: 0.2863 - val_accuracy: 0.8970\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 51s 27ms/step - loss: 0.2459 - accuracy: 0.9075 - val_loss: 0.2741 - val_accuracy: 0.9020\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 54s 29ms/step - loss: 0.2132 - accuracy: 0.9201 - val_loss: 0.2640 - val_accuracy: 0.9011\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 49s 26ms/step - loss: 0.1854 - accuracy: 0.9302 - val_loss: 0.2683 - val_accuracy: 0.9062\n",
            "Epoch 5 validation accuracy: 0.9062\n",
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 49s 26ms/step - loss: 0.1623 - accuracy: 0.9391 - val_loss: 0.2746 - val_accuracy: 0.9059\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 49s 26ms/step - loss: 0.1409 - accuracy: 0.9463 - val_loss: 0.2700 - val_accuracy: 0.9086\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 48s 26ms/step - loss: 0.1233 - accuracy: 0.9532 - val_loss: 0.2761 - val_accuracy: 0.9088\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 49s 26ms/step - loss: 0.1067 - accuracy: 0.9588 - val_loss: 0.2924 - val_accuracy: 0.9135\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 49s 26ms/step - loss: 0.0927 - accuracy: 0.9643 - val_loss: 0.3353 - val_accuracy: 0.9085\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 48s 26ms/step - loss: 0.0811 - accuracy: 0.9687 - val_loss: 0.3808 - val_accuracy: 0.9075\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 49s 26ms/step - loss: 0.0727 - accuracy: 0.9718 - val_loss: 0.3820 - val_accuracy: 0.9101\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 54s 29ms/step - loss: 0.0645 - accuracy: 0.9758 - val_loss: 0.3784 - val_accuracy: 0.9137\n",
            "Epoch 9/10\n",
            "1875/1875 [==============================] - 57s 30ms/step - loss: 0.0604 - accuracy: 0.9772 - val_loss: 0.4668 - val_accuracy: 0.9101\n",
            "Epoch 10/10\n",
            "1875/1875 [==============================] - 56s 30ms/step - loss: 0.0526 - accuracy: 0.9803 - val_loss: 0.4577 - val_accuracy: 0.9097\n",
            "Epoch 10 validation accuracy: 0.9097\n",
            "Epoch 1/15\n",
            "1875/1875 [==============================] - 49s 26ms/step - loss: 0.0502 - accuracy: 0.9816 - val_loss: 0.5211 - val_accuracy: 0.9052\n",
            "Epoch 2/15\n",
            "1875/1875 [==============================] - 55s 30ms/step - loss: 0.0462 - accuracy: 0.9840 - val_loss: 0.5547 - val_accuracy: 0.9065\n",
            "Epoch 3/15\n",
            "1875/1875 [==============================] - 58s 31ms/step - loss: 0.0447 - accuracy: 0.9839 - val_loss: 0.5126 - val_accuracy: 0.9090\n",
            "Epoch 4/15\n",
            "1875/1875 [==============================] - 49s 26ms/step - loss: 0.0390 - accuracy: 0.9860 - val_loss: 0.5248 - val_accuracy: 0.9116\n",
            "Epoch 5/15\n",
            "1875/1875 [==============================] - 51s 27ms/step - loss: 0.0393 - accuracy: 0.9862 - val_loss: 0.5364 - val_accuracy: 0.9055\n",
            "Epoch 6/15\n",
            "1875/1875 [==============================] - 50s 27ms/step - loss: 0.0402 - accuracy: 0.9864 - val_loss: 0.5571 - val_accuracy: 0.9128\n",
            "Epoch 7/15\n",
            "1875/1875 [==============================] - 51s 27ms/step - loss: 0.0353 - accuracy: 0.9876 - val_loss: 0.6207 - val_accuracy: 0.9083\n",
            "Epoch 8/15\n",
            "1875/1875 [==============================] - 46s 25ms/step - loss: 0.0342 - accuracy: 0.9884 - val_loss: 0.6115 - val_accuracy: 0.9070\n",
            "Epoch 9/15\n",
            "1875/1875 [==============================] - 47s 25ms/step - loss: 0.0343 - accuracy: 0.9888 - val_loss: 0.6912 - val_accuracy: 0.9029\n",
            "Epoch 10/15\n",
            "1875/1875 [==============================] - 48s 26ms/step - loss: 0.0350 - accuracy: 0.9886 - val_loss: 0.6775 - val_accuracy: 0.9120\n",
            "Epoch 11/15\n",
            "1875/1875 [==============================] - 48s 25ms/step - loss: 0.0309 - accuracy: 0.9898 - val_loss: 0.7240 - val_accuracy: 0.9119\n",
            "Epoch 12/15\n",
            "1875/1875 [==============================] - 48s 25ms/step - loss: 0.0314 - accuracy: 0.9897 - val_loss: 0.7142 - val_accuracy: 0.9130\n",
            "Epoch 13/15\n",
            "1875/1875 [==============================] - 48s 26ms/step - loss: 0.0334 - accuracy: 0.9889 - val_loss: 0.7252 - val_accuracy: 0.9098\n",
            "Epoch 14/15\n",
            "1875/1875 [==============================] - 48s 26ms/step - loss: 0.0279 - accuracy: 0.9908 - val_loss: 0.7601 - val_accuracy: 0.9097\n",
            "Epoch 15/15\n",
            "1875/1875 [==============================] - 55s 29ms/step - loss: 0.0328 - accuracy: 0.9894 - val_loss: 0.7577 - val_accuracy: 0.9139\n",
            "Epoch 15 validation accuracy: 0.9139\n",
            "Epoch 1/20\n",
            "1875/1875 [==============================] - 51s 27ms/step - loss: 0.0299 - accuracy: 0.9906 - val_loss: 0.7495 - val_accuracy: 0.9098\n",
            "Epoch 2/20\n",
            "1875/1875 [==============================] - 48s 25ms/step - loss: 0.0312 - accuracy: 0.9905 - val_loss: 0.8680 - val_accuracy: 0.9045\n",
            "Epoch 3/20\n",
            "1875/1875 [==============================] - 49s 26ms/step - loss: 0.0300 - accuracy: 0.9909 - val_loss: 0.7741 - val_accuracy: 0.9067\n",
            "Epoch 4/20\n",
            "1875/1875 [==============================] - 56s 30ms/step - loss: 0.0300 - accuracy: 0.9910 - val_loss: 0.7969 - val_accuracy: 0.9087\n",
            "Epoch 5/20\n",
            "1875/1875 [==============================] - 56s 30ms/step - loss: 0.0272 - accuracy: 0.9918 - val_loss: 0.9006 - val_accuracy: 0.9123\n",
            "Epoch 6/20\n",
            "1875/1875 [==============================] - 47s 25ms/step - loss: 0.0294 - accuracy: 0.9906 - val_loss: 0.8373 - val_accuracy: 0.9122\n",
            "Epoch 7/20\n",
            "1875/1875 [==============================] - 52s 28ms/step - loss: 0.0282 - accuracy: 0.9916 - val_loss: 0.9227 - val_accuracy: 0.9102\n",
            "Epoch 8/20\n",
            "1875/1875 [==============================] - 55s 29ms/step - loss: 0.0227 - accuracy: 0.9928 - val_loss: 0.9645 - val_accuracy: 0.9041\n",
            "Epoch 9/20\n",
            "1875/1875 [==============================] - 47s 25ms/step - loss: 0.0294 - accuracy: 0.9914 - val_loss: 0.9578 - val_accuracy: 0.9028\n",
            "Epoch 10/20\n",
            "1875/1875 [==============================] - 49s 26ms/step - loss: 0.0248 - accuracy: 0.9925 - val_loss: 0.8853 - val_accuracy: 0.9068\n",
            "Epoch 11/20\n",
            "1875/1875 [==============================] - 49s 26ms/step - loss: 0.0274 - accuracy: 0.9918 - val_loss: 0.9388 - val_accuracy: 0.9112\n",
            "Epoch 12/20\n",
            "1875/1875 [==============================] - 50s 26ms/step - loss: 0.0259 - accuracy: 0.9926 - val_loss: 0.9594 - val_accuracy: 0.9075\n",
            "Epoch 13/20\n",
            "1875/1875 [==============================] - 57s 30ms/step - loss: 0.0287 - accuracy: 0.9920 - val_loss: 0.9245 - val_accuracy: 0.9016\n",
            "Epoch 14/20\n",
            "1875/1875 [==============================] - 49s 26ms/step - loss: 0.0262 - accuracy: 0.9925 - val_loss: 0.9590 - val_accuracy: 0.9056\n",
            "Epoch 15/20\n",
            "1875/1875 [==============================] - 49s 26ms/step - loss: 0.0248 - accuracy: 0.9930 - val_loss: 0.9316 - val_accuracy: 0.9088\n",
            "Epoch 16/20\n",
            "1875/1875 [==============================] - 51s 27ms/step - loss: 0.0281 - accuracy: 0.9919 - val_loss: 1.0171 - val_accuracy: 0.9114\n",
            "Epoch 17/20\n",
            "1875/1875 [==============================] - 58s 31ms/step - loss: 0.0259 - accuracy: 0.9929 - val_loss: 1.1351 - val_accuracy: 0.9028\n",
            "Epoch 18/20\n",
            "1875/1875 [==============================] - 57s 30ms/step - loss: 0.0255 - accuracy: 0.9930 - val_loss: 1.0561 - val_accuracy: 0.9065\n",
            "Epoch 19/20\n",
            "1875/1875 [==============================] - 55s 29ms/step - loss: 0.0295 - accuracy: 0.9925 - val_loss: 1.0704 - val_accuracy: 0.9044\n",
            "Epoch 20/20\n",
            "1875/1875 [==============================] - 49s 26ms/step - loss: 0.0245 - accuracy: 0.9932 - val_loss: 1.1270 - val_accuracy: 0.9095\n",
            "Epoch 20 validation accuracy: 0.9095\n",
            "\n",
            "Best epoch: 15\n",
            "Epoch 1/15\n",
            "1875/1875 [==============================] - 50s 27ms/step - loss: 0.0261 - accuracy: 0.9930 - val_loss: 1.0651 - val_accuracy: 0.9059\n",
            "Epoch 2/15\n",
            "1875/1875 [==============================] - 49s 26ms/step - loss: 0.0264 - accuracy: 0.9927 - val_loss: 1.1328 - val_accuracy: 0.9064\n",
            "Epoch 3/15\n",
            "1875/1875 [==============================] - 56s 30ms/step - loss: 0.0214 - accuracy: 0.9937 - val_loss: 1.1179 - val_accuracy: 0.9057\n",
            "Epoch 4/15\n",
            "1875/1875 [==============================] - 54s 29ms/step - loss: 0.0302 - accuracy: 0.9922 - val_loss: 1.2188 - val_accuracy: 0.9026\n",
            "Epoch 5/15\n",
            "1875/1875 [==============================] - 49s 26ms/step - loss: 0.0238 - accuracy: 0.9938 - val_loss: 1.1787 - val_accuracy: 0.9076\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 6/15\n",
            "1875/1875 [==============================] - 55s 29ms/step - loss: 0.0263 - accuracy: 0.9928 - val_loss: 1.3330 - val_accuracy: 0.9090\n",
            "Epoch 7/15\n",
            "1875/1875 [==============================] - 50s 27ms/step - loss: 0.0244 - accuracy: 0.9937 - val_loss: 1.1870 - val_accuracy: 0.9080\n",
            "Epoch 8/15\n",
            "1875/1875 [==============================] - 48s 26ms/step - loss: 0.0260 - accuracy: 0.9939 - val_loss: 1.1651 - val_accuracy: 0.9074\n",
            "Epoch 9/15\n",
            "1875/1875 [==============================] - 48s 26ms/step - loss: 0.0261 - accuracy: 0.9938 - val_loss: 1.0866 - val_accuracy: 0.9086\n",
            "Epoch 10/15\n",
            "1875/1875 [==============================] - 51s 27ms/step - loss: 0.0283 - accuracy: 0.9933 - val_loss: 1.1573 - val_accuracy: 0.9010\n",
            "Epoch 11/15\n",
            "1875/1875 [==============================] - 50s 27ms/step - loss: 0.0195 - accuracy: 0.9943 - val_loss: 1.2099 - val_accuracy: 0.9079\n",
            "Epoch 12/15\n",
            "1875/1875 [==============================] - 51s 27ms/step - loss: 0.0262 - accuracy: 0.9934 - val_loss: 1.2240 - val_accuracy: 0.9101\n",
            "Epoch 13/15\n",
            "1875/1875 [==============================] - 51s 27ms/step - loss: 0.0242 - accuracy: 0.9937 - val_loss: 1.3149 - val_accuracy: 0.9113\n",
            "Epoch 14/15\n",
            "1875/1875 [==============================] - 50s 27ms/step - loss: 0.0283 - accuracy: 0.9935 - val_loss: 1.2648 - val_accuracy: 0.9094\n",
            "Epoch 15/15\n",
            "1875/1875 [==============================] - 50s 27ms/step - loss: 0.0231 - accuracy: 0.9940 - val_loss: 1.3527 - val_accuracy: 0.9014\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 1.3527 - accuracy: 0.9014\n",
            "Test accuracy: 0.9014000296592712\n",
            "Best epoch: 15\n"
          ]
        }
      ],
      "source": [
        "best_epoch = find_best_epoch()\n",
        "print(\"Best epoch:\", best_epoch)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b9c1d94c",
      "metadata": {
        "id": "b9c1d94c"
      },
      "source": [
        "# Train Model with MNIST"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "77df31b3",
      "metadata": {
        "id": "77df31b3"
      },
      "outputs": [],
      "source": [
        "def train_and_evaluate_model(num_epochs_list):\n",
        "    # Load the MNIST dataset\n",
        "    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "    # Preprocess the data\n",
        "    x_train = x_train.astype('float32') / 255.\n",
        "    x_test = x_test.astype('float32') / 255.\n",
        "    x_train = np.expand_dims(x_train, axis=-1)\n",
        "    x_test = np.expand_dims(x_test, axis=-1)\n",
        "    y_train = keras.utils.to_categorical(y_train, 10)\n",
        "    y_test = keras.utils.to_categorical(y_test, 10)\n",
        "\n",
        "    # Define the model\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(20, (5, 5), activation='relu', input_shape=(28, 28, 1)))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Conv2D(50, (5, 5), activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(500, activation='relu'))\n",
        "    model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "    # Train the model for each number of epochs and evaluate its accuracy\n",
        "    best_accuracy = 0\n",
        "    best_num_epochs = 0\n",
        "    for num_epochs in num_epochs_list:\n",
        "        model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "        model.fit(x_train, y_train, epochs=num_epochs, batch_size=128, validation_data=(x_test, y_test), verbose=0)\n",
        "        accuracy = model.evaluate(x_test, y_test, verbose=0)[1]\n",
        "        print(f'Accuracy after {num_epochs} epochs: {accuracy}')\n",
        "        if accuracy > best_accuracy:\n",
        "            best_accuracy = accuracy\n",
        "            best_num_epochs = num_epochs\n",
        "\n",
        "    print(f'Best accuracy ({best_accuracy}) achieved after {best_num_epochs} epochs')\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e9033be3",
      "metadata": {
        "id": "e9033be3",
        "outputId": "8b14724d-0f3d-41ac-86ec-6a38549aa1cc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy after 5 epochs: 0.991100013256073\n",
            "Accuracy after 10 epochs: 0.9901999831199646\n",
            "Accuracy after 15 epochs: 0.991100013256073\n",
            "Accuracy after 20 epochs: 0.9926999807357788\n",
            "Best accuracy (0.9926999807357788) achieved after 20 epochs\n"
          ]
        }
      ],
      "source": [
        "model = train_and_evaluate_model([5, 10, 15, 20])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9b168372",
      "metadata": {
        "id": "9b168372"
      },
      "source": [
        "# Train Model with Fashion-MNIST"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "af55602e",
      "metadata": {
        "id": "af55602e"
      },
      "outputs": [],
      "source": [
        "def train_and_evaluate_Model_FMNIST():\n",
        "    # Load the Fashion-MNIST dataset\n",
        "    (x_train, y_train), (x_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
        "\n",
        "    # Preprocess the data\n",
        "    x_train = x_train.astype(\"float32\") / 255.0\n",
        "    x_test = x_test.astype(\"float32\") / 255.0\n",
        "    x_train = x_train.reshape(-1, 28, 28, 1)\n",
        "    x_test = x_test.reshape(-1, 28, 28, 1)\n",
        "\n",
        "    # Define the model\n",
        "    model = keras.Sequential(\n",
        "        [\n",
        "            layers.Conv2D(32, kernel_size=3, activation=\"relu\", input_shape=(28, 28, 1)),\n",
        "            layers.MaxPooling2D(),\n",
        "            layers.Conv2D(64, kernel_size=3, activation=\"relu\"),\n",
        "            layers.MaxPooling2D(),\n",
        "            layers.Conv2D(128, kernel_size=3, activation=\"relu\"),\n",
        "            layers.Flatten(),\n",
        "            layers.Dense(512, activation=\"relu\"),\n",
        "            layers.Dense(10, activation=\"softmax\"),\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "    # Train the model with different number of epochs\n",
        "    epochs = [5, 10, 15, 20]\n",
        "    best_epoch = 0\n",
        "    best_val_acc = 0.0\n",
        "    for epoch in epochs:\n",
        "        history = model.fit(x_train, y_train, epochs=epoch, validation_data=(x_test, y_test))\n",
        "        val_acc = history.history['val_accuracy'][-1]\n",
        "        print(f\"Epoch {epoch} validation accuracy: {val_acc:.4f}\")\n",
        "        if val_acc > best_val_acc:\n",
        "            best_val_acc = val_acc\n",
        "            best_epoch = epoch\n",
        "\n",
        "    # Return the best epoch\n",
        "    print(f\"\\nBest epoch: {best_epoch}\")\n",
        "    return best_epoch\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "41107d77",
      "metadata": {
        "id": "41107d77",
        "outputId": "bf277db2-1018-40eb-bd18-f0a71b1f87a2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 54s 28ms/step - loss: 0.4467 - accuracy: 0.8353 - val_loss: 0.3749 - val_accuracy: 0.8656\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 68s 36ms/step - loss: 0.2977 - accuracy: 0.8900 - val_loss: 0.3084 - val_accuracy: 0.8821\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 51s 27ms/step - loss: 0.2519 - accuracy: 0.9054 - val_loss: 0.2843 - val_accuracy: 0.8932\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 51s 27ms/step - loss: 0.2200 - accuracy: 0.9168 - val_loss: 0.2619 - val_accuracy: 0.9049\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 54s 29ms/step - loss: 0.1951 - accuracy: 0.9262 - val_loss: 0.2831 - val_accuracy: 0.8978\n",
            "Epoch 5 validation accuracy: 0.8978\n",
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 52s 28ms/step - loss: 0.1710 - accuracy: 0.9356 - val_loss: 0.2745 - val_accuracy: 0.9067\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 54s 29ms/step - loss: 0.1502 - accuracy: 0.9428 - val_loss: 0.2702 - val_accuracy: 0.9115\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 49s 26ms/step - loss: 0.1323 - accuracy: 0.9490 - val_loss: 0.2806 - val_accuracy: 0.9113\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 50s 27ms/step - loss: 0.1170 - accuracy: 0.9554 - val_loss: 0.3556 - val_accuracy: 0.9007\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 49s 26ms/step - loss: 0.1020 - accuracy: 0.9610 - val_loss: 0.3145 - val_accuracy: 0.9138\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 54s 29ms/step - loss: 0.0921 - accuracy: 0.9639 - val_loss: 0.3471 - val_accuracy: 0.9132\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 56s 30ms/step - loss: 0.0795 - accuracy: 0.9696 - val_loss: 0.3791 - val_accuracy: 0.9081\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 50s 26ms/step - loss: 0.0753 - accuracy: 0.9713 - val_loss: 0.4134 - val_accuracy: 0.9082\n",
            "Epoch 9/10\n",
            "1875/1875 [==============================] - 51s 27ms/step - loss: 0.0673 - accuracy: 0.9746 - val_loss: 0.4385 - val_accuracy: 0.9142\n",
            "Epoch 10/10\n",
            "1875/1875 [==============================] - 55s 29ms/step - loss: 0.0595 - accuracy: 0.9776 - val_loss: 0.5170 - val_accuracy: 0.9096\n",
            "Epoch 10 validation accuracy: 0.9096\n",
            "Epoch 1/15\n",
            "1875/1875 [==============================] - 54s 29ms/step - loss: 0.0570 - accuracy: 0.9781 - val_loss: 0.4828 - val_accuracy: 0.9063\n",
            "Epoch 2/15\n",
            "1875/1875 [==============================] - 56s 30ms/step - loss: 0.0509 - accuracy: 0.9807 - val_loss: 0.4736 - val_accuracy: 0.9073\n",
            "Epoch 3/15\n",
            "1875/1875 [==============================] - 54s 29ms/step - loss: 0.0469 - accuracy: 0.9833 - val_loss: 0.5031 - val_accuracy: 0.9137\n",
            "Epoch 4/15\n",
            "1875/1875 [==============================] - 52s 28ms/step - loss: 0.0491 - accuracy: 0.9826 - val_loss: 0.5182 - val_accuracy: 0.9066\n",
            "Epoch 5/15\n",
            "1875/1875 [==============================] - 62s 33ms/step - loss: 0.0448 - accuracy: 0.9841 - val_loss: 0.5586 - val_accuracy: 0.9075\n",
            "Epoch 6/15\n",
            "1875/1875 [==============================] - 65s 35ms/step - loss: 0.0437 - accuracy: 0.9837 - val_loss: 0.5476 - val_accuracy: 0.9112\n",
            "Epoch 7/15\n",
            "1875/1875 [==============================] - 54s 29ms/step - loss: 0.0406 - accuracy: 0.9853 - val_loss: 0.6049 - val_accuracy: 0.9088\n",
            "Epoch 8/15\n",
            "1875/1875 [==============================] - 53s 28ms/step - loss: 0.0381 - accuracy: 0.9866 - val_loss: 0.6175 - val_accuracy: 0.9095\n",
            "Epoch 9/15\n",
            "1875/1875 [==============================] - 53s 28ms/step - loss: 0.0356 - accuracy: 0.9882 - val_loss: 0.6330 - val_accuracy: 0.9112\n",
            "Epoch 10/15\n",
            "1875/1875 [==============================] - 52s 28ms/step - loss: 0.0397 - accuracy: 0.9862 - val_loss: 0.6500 - val_accuracy: 0.9086\n",
            "Epoch 11/15\n",
            "1875/1875 [==============================] - 50s 27ms/step - loss: 0.0356 - accuracy: 0.9878 - val_loss: 0.7226 - val_accuracy: 0.9067\n",
            "Epoch 12/15\n",
            "1875/1875 [==============================] - 53s 28ms/step - loss: 0.0337 - accuracy: 0.9885 - val_loss: 0.7173 - val_accuracy: 0.9052\n",
            "Epoch 13/15\n",
            "1875/1875 [==============================] - 54s 29ms/step - loss: 0.0347 - accuracy: 0.9880 - val_loss: 0.7930 - val_accuracy: 0.9062\n",
            "Epoch 14/15\n",
            "1875/1875 [==============================] - 57s 30ms/step - loss: 0.0334 - accuracy: 0.9890 - val_loss: 0.7374 - val_accuracy: 0.9098\n",
            "Epoch 15/15\n",
            "1875/1875 [==============================] - 59s 31ms/step - loss: 0.0354 - accuracy: 0.9881 - val_loss: 0.7411 - val_accuracy: 0.9045\n",
            "Epoch 15 validation accuracy: 0.9045\n",
            "Epoch 1/20\n",
            "1875/1875 [==============================] - 54s 29ms/step - loss: 0.0300 - accuracy: 0.9902 - val_loss: 0.7455 - val_accuracy: 0.9064\n",
            "Epoch 2/20\n",
            "1875/1875 [==============================] - 58s 31ms/step - loss: 0.0285 - accuracy: 0.9908 - val_loss: 0.8621 - val_accuracy: 0.9062\n",
            "Epoch 3/20\n",
            "1875/1875 [==============================] - 54s 29ms/step - loss: 0.0337 - accuracy: 0.9888 - val_loss: 0.8106 - val_accuracy: 0.9106\n",
            "Epoch 4/20\n",
            "1875/1875 [==============================] - 55s 30ms/step - loss: 0.0319 - accuracy: 0.9895 - val_loss: 0.7663 - val_accuracy: 0.9092\n",
            "Epoch 5/20\n",
            "1875/1875 [==============================] - 66s 35ms/step - loss: 0.0312 - accuracy: 0.9907 - val_loss: 0.8389 - val_accuracy: 0.9117\n",
            "Epoch 6/20\n",
            "1875/1875 [==============================] - 61s 33ms/step - loss: 0.0282 - accuracy: 0.9915 - val_loss: 0.7679 - val_accuracy: 0.9097\n",
            "Epoch 7/20\n",
            "1875/1875 [==============================] - 51s 27ms/step - loss: 0.0277 - accuracy: 0.9910 - val_loss: 0.9748 - val_accuracy: 0.9069\n",
            "Epoch 8/20\n",
            "1875/1875 [==============================] - 52s 28ms/step - loss: 0.0322 - accuracy: 0.9898 - val_loss: 0.9141 - val_accuracy: 0.9087\n",
            "Epoch 9/20\n",
            "1875/1875 [==============================] - 52s 28ms/step - loss: 0.0278 - accuracy: 0.9911 - val_loss: 0.8694 - val_accuracy: 0.9053\n",
            "Epoch 10/20\n",
            "1875/1875 [==============================] - 52s 28ms/step - loss: 0.0297 - accuracy: 0.9910 - val_loss: 0.8660 - val_accuracy: 0.9065\n",
            "Epoch 11/20\n",
            "1875/1875 [==============================] - 53s 28ms/step - loss: 0.0316 - accuracy: 0.9910 - val_loss: 0.9380 - val_accuracy: 0.9071\n",
            "Epoch 12/20\n",
            "1875/1875 [==============================] - 51s 27ms/step - loss: 0.0283 - accuracy: 0.9920 - val_loss: 0.9245 - val_accuracy: 0.9077\n",
            "Epoch 13/20\n",
            "1875/1875 [==============================] - 53s 28ms/step - loss: 0.0296 - accuracy: 0.9913 - val_loss: 0.9502 - val_accuracy: 0.9075\n",
            "Epoch 14/20\n",
            "1875/1875 [==============================] - 52s 28ms/step - loss: 0.0281 - accuracy: 0.9915 - val_loss: 0.9742 - val_accuracy: 0.9087\n",
            "Epoch 15/20\n",
            "1875/1875 [==============================] - 54s 29ms/step - loss: 0.0270 - accuracy: 0.9927 - val_loss: 0.9281 - val_accuracy: 0.9071\n",
            "Epoch 16/20\n",
            "1875/1875 [==============================] - 53s 28ms/step - loss: 0.0288 - accuracy: 0.9916 - val_loss: 0.9896 - val_accuracy: 0.9070\n",
            "Epoch 17/20\n",
            "1875/1875 [==============================] - 53s 28ms/step - loss: 0.0276 - accuracy: 0.9918 - val_loss: 1.0083 - val_accuracy: 0.9089\n",
            "Epoch 18/20\n",
            "1875/1875 [==============================] - 55s 29ms/step - loss: 0.0279 - accuracy: 0.9922 - val_loss: 1.1336 - val_accuracy: 0.9061\n",
            "Epoch 19/20\n",
            "1875/1875 [==============================] - 53s 28ms/step - loss: 0.0279 - accuracy: 0.9920 - val_loss: 1.0048 - val_accuracy: 0.9078\n",
            "Epoch 20/20\n",
            "1875/1875 [==============================] - 55s 29ms/step - loss: 0.0289 - accuracy: 0.9924 - val_loss: 1.0801 - val_accuracy: 0.9126\n",
            "Epoch 20 validation accuracy: 0.9126\n",
            "\n",
            "Best epoch: 20\n",
            "Best epoch: 20\n"
          ]
        }
      ],
      "source": [
        "best_epoch = train_and_evaluate_model()\n",
        "print(f\"Best epoch: {best_epoch}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "661386ed",
      "metadata": {
        "id": "661386ed"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}